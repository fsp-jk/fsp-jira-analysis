{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REPORT CONFIGURATION\n",
    "This section should be populated with the following values:\n",
    "* Query - The JIRA JQL query to identify the relevant scope\n",
    "* Title - A description of the scope to include in the reports.\n",
    "* Days to Extrapolate - For forecasting completion & creation rates, how much historically data should be considered.  Generally, data should be considered in 7-day blocks to avoid any weekend bias.\n",
    "* Start Dates - The first date to include in reports.\n",
    "* End Dates - The last date to include in reports.  This date can be future dated.  All dates beyond the current date will be based on extrapolation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jira_reconnect = False # You will only be prompted to connect the first time.  If credentials are entered incorrectly, you can change this to true to reconnect.\n",
    "\n",
    "# Examples:\n",
    "# query = 'issuekey in portfolioChildIssuesOf(\"FSP-8899\")'\n",
    "# title = \"Dev Distractions Scope\"\n",
    "# days_to_extrapolate = 14\n",
    "# start_date=\"2024-07-01\"\n",
    "# end_date=\"2024-10-01\"\n",
    "\n",
    "query = 'issuekey in portfolioChildIssuesOf(\"PWD-410\")'\n",
    "title = \"Pilotbase Milestone 2 Scope\"\n",
    "days_to_extrapolate = 14\n",
    "start_date=\"2024-09-01\"\n",
    "end_date=\"2024-09-30\"\n",
    "\n",
    "# query = 'issuekey in portfolioChildIssuesOf(\"FSP-7973\")'\n",
    "# title = \"Student Financing with Stratus\"\n",
    "# days_to_extrapolate = 14\n",
    "# start_date=\"2024-08-01\"\n",
    "# end_date=\"2024-12-01\"\n",
    "\n",
    "# query = 'issuekey in portfolioChildIssuesOf(\"FSP-7973\")'\n",
    "# title = \"Stratus MVP Integration Scope\"\n",
    "# days_to_extrapolate = 14\n",
    "# start_date=\"2024-06-15\"\n",
    "# end_date=\"2024-09-01\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SETUP CONNECTIONS AND CONFIGURATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependency install and import -- do both pip and pip3 to avoid issues.\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "    \n",
    "!pip -q install jira\n",
    "!pip3 -q install jira\n",
    "!pip -q install tqdm\n",
    "!pip3 -q install tqdm\n",
    "!pip -q install matplotlib\n",
    "!pip3 -q install matplotlib\n",
    "!pip -q install pandas\n",
    "!pip3 -q install pandas\n",
    "\n",
    "from jira import JIRA\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from datetime import *\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Jira Connection\n",
    "from jira_fsp_extracts import jira_connect\n",
    "\n",
    "j = None if 'j' not in globals() else j\n",
    "j = jira_connect(prompt_for_reconnect = jira_reconnect, existing_connection = j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REFERENCE VALUES\n",
    "from jira_references import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUPPORT FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# def generate_burndown_chart() # GENERATE A BURNDOWN CHART WITH TOTAL SCOPE, RESOLVED SCOPE, REMAINING SCOPE\n",
    "def generate_burndown_chart(df, start_date=None, end_date=None, extrapolate_days=None, title=None):\n",
    "    \"\"\"\n",
    "    Generate a burndown chart from a DataFrame containing Jira issue data.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): DataFrame containing columns 'Created Date', 'Resolution Date', and 'Status'.\n",
    "\n",
    "    Returns:\n",
    "    None: Displays the burndown chart.\n",
    "    \"\"\"\n",
    "\n",
    "    # Set the start and end date for the burndown chart\n",
    "    if start_date is None:\n",
    "        start_date = df['Created Date'].min()\n",
    "    else: \n",
    "        start_date = pd.to_datetime(start_date).tz_localize(None)\n",
    "\n",
    "    if end_date is None:\n",
    "        end_date = df['Resolution Date'].max()\n",
    "    else: \n",
    "        end_date = pd.to_datetime(end_date).tz_localize(None)\n",
    "  \n",
    "    # Ensure both start_date and end_date are timezone-naive (or have the same timezone)\n",
    "    if start_date.tzinfo is not None:\n",
    "        start_date = start_date.tz_convert(None)\n",
    "    if end_date.tzinfo is not None:\n",
    "        end_date = end_date.tz_convert(None)\n",
    "        \n",
    "    now = pd.Timestamp('now').normalize()\n",
    "    \n",
    "    if title is None:\n",
    "        title = 'Burndown Chart'\n",
    "        \n",
    "    # Create a date range\n",
    "    date_range = pd.date_range(start=start_date, end=end_date)\n",
    "\n",
    "    # Initialize a DataFrame to hold the burndown data\n",
    "    burndown_data = pd.DataFrame(date_range, columns=['Date'])\n",
    "    burndown_data['Total Tasks'] = 0\n",
    "    burndown_data['Remaining Tasks'] = 0\n",
    "    burndown_data['Resolved Tasks'] = 0\n",
    "\n",
    "    # Initialize extrapolation values\n",
    "    daily_resolution_rate = None\n",
    "    daily_creation_rate = None\n",
    "\n",
    "    # Calculate the number of tasks remaining on each date\n",
    "    for i, row in burndown_data.iterrows():\n",
    "        date = row['Date']\n",
    "        \n",
    "        if date <= now:\n",
    "            # prior to today we have actuals\n",
    "            total_tasks = df[(df['Created Date'] <= date)].shape[0]\n",
    "            resolved_tasks = df[(df['Resolution Date'] <= date)].shape[0]\n",
    "            remaining_tasks = total_tasks - resolved_tasks\n",
    "            \n",
    "            burndown_data.at[i, 'Total Tasks'] = total_tasks\n",
    "            burndown_data.at[i, 'Remaining Tasks'] = remaining_tasks\n",
    "            burndown_data.at[i, 'Resolved Tasks'] = resolved_tasks\n",
    "            burndown_data.at[i, 'Total Tasks (F)'] = None\n",
    "            burndown_data.at[i, 'Remaining Tasks (F)'] = None\n",
    "            burndown_data.at[i, 'Resolved Tasks (F)'] = None\n",
    "        else:\n",
    "            # Extrapolate future data if extrapolate_days is provided\n",
    "            burndown_data.at[i, 'Total Tasks'] = None\n",
    "            burndown_data.at[i, 'Remaining Tasks'] = None\n",
    "            burndown_data.at[i, 'Resolved Tasks'] = None\n",
    "            burndown_data.at[i, 'Total Tasks (F)'] = None\n",
    "            burndown_data.at[i, 'Remaining Tasks (F)'] = None\n",
    "            burndown_data.at[i, 'Resolved Tasks (F)'] = None\n",
    "            \n",
    "            if extrapolate_days is not None:\n",
    "                # Calculate the trajectories the first time\n",
    "                if daily_resolution_rate is None or daily_creation_rate is None:           \n",
    "                    # Calculate the trajectory based on the last \"X\" days\n",
    "                    trajectory_period = min(extrapolate_days, len(date_range))\n",
    "                    recent_data = burndown_data[(burndown_data['Date'] <= now)].tail(trajectory_period)\n",
    "                    \n",
    "                    daily_resolution_rate = recent_data['Resolved Tasks'].diff().mean()\n",
    "                    daily_creation_rate = recent_data['Total Tasks'].diff().mean()\n",
    "                    print(f\"Extrapolated outcomes based on {trajectory_period} days\")\n",
    "                    print(f\"-- Daily Resolution Rate: {round(daily_resolution_rate,2)}\")\n",
    "                    print(f\"-- Daily Creation Rate: {round(daily_creation_rate,2)}\")\n",
    "                    \n",
    "                    burndown_data.at[i-1, 'Total Tasks (F)'] = burndown_data.at[i-1, 'Total Tasks']\n",
    "                    burndown_data.at[i-1, 'Remaining Tasks (F)'] = burndown_data.at[i-1, 'Remaining Tasks']\n",
    "                    burndown_data.at[i-1, 'Resolved Tasks (F)'] = burndown_data.at[i-1, 'Resolved Tasks']\n",
    "\n",
    "                        \n",
    "                burndown_data.at[i, 'Total Tasks (F)'] = burndown_data.at[i-1, 'Total Tasks (F)'] + daily_creation_rate\n",
    "                burndown_data.at[i, 'Remaining Tasks (F)'] = burndown_data.at[i-1, 'Remaining Tasks (F)'] + daily_creation_rate - daily_resolution_rate\n",
    "                burndown_data.at[i, 'Resolved Tasks (F)'] = burndown_data.at[i-1, 'Resolved Tasks (F)'] + daily_resolution_rate\n",
    "            \n",
    "\n",
    "\n",
    "    # Plot the burndown chart\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.plot(burndown_data['Date'], burndown_data['Total Tasks'], color='red', linestyle='-', label='Total Tasks')\n",
    "    plt.plot(burndown_data['Date'], burndown_data['Remaining Tasks'], color='orange', linestyle='-', label='Remaining Tasks')\n",
    "    plt.plot(burndown_data['Date'], burndown_data['Resolved Tasks'], color='green', linestyle='-', label='Resolved Tasks')\n",
    "\n",
    "    if extrapolate_days is not None and (daily_resolution_rate is not None or daily_creation_rate is not None):\n",
    "        if not burndown_data['Total Tasks (F)'].isna().all:\n",
    "            plt.plot(burndown_data['Date'], burndown_data['Total Tasks (F)'], color='red', linestyle='dashed')\n",
    "        if not burndown_data['Remaining Tasks (F)'].isna().all:\n",
    "            plt.plot(burndown_data['Date'], burndown_data['Remaining Tasks (F)'], color='orange', linestyle='dashed')\n",
    "        if not burndown_data['Resolved Tasks (F)'].isna().all:\n",
    "            plt.plot(burndown_data['Date'], burndown_data['Resolved Tasks (F)'], color='green', linestyle='dashed')\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Tickets')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.xticks(rotation=45)\n",
    "    #plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# def def generate_stacked_bar_chart() # GENERATE A CHART WITH TOTAL SCOPE BROKEN DOWN BY STATUS\n",
    "def generate_stacked_bar_chart(df, start_date=None, end_date=None, extrapolate_days=None, title=None):\n",
    "    \"\"\"\n",
    "    Generate a stacked bar chart based on statuses over time.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): DataFrame containing columns 'Created Date', 'Resolution Date', and 'Status'.\n",
    "\n",
    "    Returns:\n",
    "    None: Displays the burndown chart.\n",
    "    \"\"\"\n",
    "\n",
    "    # Set the start and end date for the burndown chart\n",
    "    if start_date is None:\n",
    "        start_date = df['Created Date'].min()\n",
    "    else: \n",
    "        start_date = pd.to_datetime(start_date).tz_localize(None)\n",
    "\n",
    "    if end_date is None:\n",
    "        end_date = df['Resolution Date'].max()\n",
    "    else: \n",
    "        end_date = pd.to_datetime(end_date).tz_localize(None)\n",
    "  \n",
    "    # Ensure both start_date and end_date are timezone-naive (or have the same timezone)\n",
    "    if start_date.tzinfo is not None:\n",
    "        start_date = start_date.tz_convert(None)\n",
    "    if end_date.tzinfo is not None:\n",
    "        end_date = end_date.tz_convert(None)\n",
    "        \n",
    "    now = pd.Timestamp('now').normalize() + pd.Timedelta(days=1)\n",
    "    \n",
    "    if title is None:\n",
    "        title = 'Stacked Bar Status Chart'\n",
    "        \n",
    "    # Create a date range\n",
    "    date_range = pd.date_range(start=start_date, end=end_date)\n",
    "\n",
    "    # Initialize a DataFrame to hold the burndown data\n",
    "    burndown_data = pd.DataFrame(date_range, columns=['Date'])\n",
    "    burndown_data['Total Tasks'] = 0\n",
    "    burndown_data['PM Backlog Tasks'] = 0\n",
    "    burndown_data['Eng Backlog Tasks'] = 0\n",
    "    burndown_data['In Development Tasks'] = 0\n",
    "    burndown_data['In Validation Tasks'] = 0\n",
    "    burndown_data['Done Tasks'] = 0\n",
    "\n",
    "    # Initialize extrapolation values\n",
    "    daily_resolution_rate = None\n",
    "    daily_creation_rate = None\n",
    "\n",
    "    # Calculate the number of tasks remaining on each date\n",
    "    for i, row in burndown_data.iterrows():\n",
    "        date = row['Date']\n",
    "        \n",
    "        if date <= now:\n",
    "            # prior to today we have actuals\n",
    "            total_tasks = df[(df['Created Date'] <= date)].shape[0]\n",
    "            done_tasks = df[(df['Done Date'] <= date)].shape[0] \n",
    "            in_validation_tasks = df[(df['Validation Date'] <= date) & ((df['Done Date'].isna()) | (df['Done Date'] > date))].shape[0] \n",
    "            in_development_tasks = df[(df['Development Date'] <= date) & ((df['Validation Date'].isna()) | (df['Validation Date'] > date)) & ((df['Done Date'].isna()) | (df['Done Date'] > date))].shape[0] \n",
    "            eng_backlog_tasks = df[(df['Eng Backlog Date'] <= date) & ((df['Development Date'].isna()) | (df['Development Date'] > date)) & ((df['Validation Date'].isna()) | (df['Validation Date'] > date)) & ((df['Done Date'].isna()) | (df['Done Date'] > date))].shape[0] \n",
    "            pm_backlog_tasks = df[(df['PM Backlog Date'] <= date) & ((df['Eng Backlog Date'].isna()) | (df['Eng Backlog Date'] > date)) & ((df['Development Date'].isna()) | (df['Development Date'] > date)) & ((df['Validation Date'].isna()) | (df['Validation Date'] > date)) & ((df['Done Date'].isna()) | (df['Done Date'] > date))].shape[0] \n",
    "            #pm_backlog_tasks = total_tasks - done_tasks - in_validation_tasks - in_development_tasks - eng_backlog_tasks\n",
    "            \n",
    "            burndown_data.at[i, 'Total Tasks'] = total_tasks\n",
    "            burndown_data.at[i, 'PM Backlog Tasks'] = pm_backlog_tasks\n",
    "            burndown_data.at[i, 'Eng Backlog Tasks'] = eng_backlog_tasks\n",
    "            burndown_data.at[i, 'In Development Tasks'] = in_development_tasks\n",
    "            burndown_data.at[i, 'In Validation Tasks'] = in_validation_tasks\n",
    "            burndown_data.at[i, 'Done Tasks'] = done_tasks\n",
    "            burndown_data.at[i, 'Total Tasks (F)'] = None\n",
    "            burndown_data.at[i, 'Done Tasks (F)'] = None\n",
    "            burndown_data.at[i, 'Remaining Tasks (F)'] = None\n",
    "        else:\n",
    "            # Extrapolate future data if extrapolate_days is provided\n",
    "            burndown_data.at[i, 'Total Tasks'] = None\n",
    "            burndown_data.at[i, 'PM Backlog Tasks'] = None\n",
    "            burndown_data.at[i, 'Eng Backlog Tasks'] = None\n",
    "            burndown_data.at[i, 'In Development Tasks'] = None\n",
    "            burndown_data.at[i, 'In Validation Tasks'] = None\n",
    "            burndown_data.at[i, 'Done Tasks'] = None\n",
    "            burndown_data.at[i, 'Total Tasks (F)'] = None\n",
    "            burndown_data.at[i, 'Done Tasks (F)'] = None\n",
    "            burndown_data.at[i, 'Remaining Tasks (F)'] = None\n",
    "            \n",
    "            if extrapolate_days is not None:\n",
    "                # Calculate the trajectories the first time\n",
    "                if daily_resolution_rate is None or daily_creation_rate is None:           \n",
    "                    # Calculate the trajectory based on the last \"X\" days\n",
    "                    trajectory_period = min(extrapolate_days, len(date_range))\n",
    "                    recent_data = burndown_data[(burndown_data['Date'] <= now)].tail(trajectory_period)\n",
    "                    \n",
    "                    daily_resolution_rate = recent_data['Done Tasks'].diff().mean()\n",
    "                    daily_creation_rate = recent_data['Total Tasks'].diff().mean()\n",
    "                    print(f\"Extrapolated outcomes based on {trajectory_period} days\")\n",
    "                    print(f\"-- Daily Resolution Rate: {round(daily_resolution_rate,2)}\")\n",
    "                    print(f\"-- Daily Creation Rate: {round(daily_creation_rate,2)}\")\n",
    "                    \n",
    "                    burndown_data.at[i-1, 'Total Tasks (F)'] = burndown_data.at[i-1, 'Total Tasks']\n",
    "                    burndown_data.at[i-1, 'Done Tasks (F)'] = burndown_data.at[i-1, 'Done Tasks']\n",
    "                    burndown_data.at[i-1, 'Remaining Tasks (F)'] = burndown_data.at[i-1, 'Total Tasks (F)'] - burndown_data.at[i-1, 'Done Tasks (F)']\n",
    "            \n",
    "                burndown_data.at[i, 'Total Tasks (F)'] = burndown_data.at[i-1, 'Total Tasks (F)'] + daily_creation_rate\n",
    "                burndown_data.at[i, 'Done Tasks (F)'] = burndown_data.at[i-1, 'Done Tasks (F)'] + daily_resolution_rate\n",
    "                if burndown_data.at[i, 'Done Tasks (F)'] < 0:\n",
    "                    burndown_data.at[i, 'Done Tasks (F)'] = 0\n",
    "                burndown_data.at[i, 'Remaining Tasks (F)'] = burndown_data.at[i, 'Total Tasks (F)'] - burndown_data.at[i, 'Done Tasks (F)']\n",
    "\n",
    "    # For troubleshooting\n",
    "    burndown_data.to_csv(\"burndown_data.csv\")\n",
    "    \n",
    "    # Plot the burndown chart\n",
    "    fig, ax = plt.subplots(figsize=(10, 4))\n",
    "    \n",
    "    ax.plot(burndown_data['Date'], burndown_data['Total Tasks'], color='black', linestyle='-', label='Total')\n",
    "\n",
    "    # Plot the stacked bars\n",
    "    ax.bar(burndown_data['Date'], burndown_data['PM Backlog Tasks'], label='PM Backlog', color='red')\n",
    "    ax.bar(burndown_data['Date'], burndown_data['Eng Backlog Tasks'], bottom=burndown_data['PM Backlog Tasks'], label='Eng Backlog', color='orange')\n",
    "    ax.bar(burndown_data['Date'], burndown_data['In Development Tasks'], bottom=burndown_data['PM Backlog Tasks']+burndown_data['Eng Backlog Tasks'], label='In Development', color='yellow')\n",
    "    ax.bar(burndown_data['Date'], burndown_data['In Validation Tasks'], bottom=burndown_data['PM Backlog Tasks']+burndown_data['Eng Backlog Tasks']+burndown_data['In Development Tasks'], label='In Validation', color='green')\n",
    "    ax.bar(burndown_data['Date'], burndown_data['Done Tasks'], bottom=burndown_data['PM Backlog Tasks']+burndown_data['Eng Backlog Tasks']+burndown_data['In Development Tasks']+burndown_data['In Validation Tasks'], label='Done', color='blue')\n",
    "\n",
    "    if extrapolate_days is not None and (daily_resolution_rate is not None or daily_creation_rate is not None):\n",
    "        forecasted_data = burndown_data[burndown_data['Done Tasks (F)'].notna()]\n",
    "        if not forecasted_data['Total Tasks (F)'].isna().all():\n",
    "            plt.plot(forecasted_data['Date'], forecasted_data['Total Tasks (F)'], color='black', linestyle='dashed')\n",
    "        if not forecasted_data['Done Tasks (F)'].isna().all():\n",
    "            ax.bar(forecasted_data['Date'], forecasted_data['Done Tasks (F)'], bottom=forecasted_data['Remaining Tasks (F)'], color='blue', alpha=0.4)\n",
    "        \n",
    "    plt.title(title)\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Tickets')\n",
    "\n",
    "    y_limit = math.ceil(max(burndown_data['Total Tasks'].max(), burndown_data['Total Tasks (F)'].max()) + 2)\n",
    "    plt.ylim(0, y_limit)\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# def generate_bar_chart() # GENERATE A BAR CHART BASED ON VOLUME FOR AN IDENTIFIED COLUMN\n",
    "def generate_bar_chart(df, column, title=None):\n",
    "    \"\"\"\n",
    "    GENERATE A BAR CHART BASED ON VOLUME FOR AN IDENTIFIED COLUMN\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): DataFrame containing columns 'Created Date', 'Resolution Date', and 'Status'.\n",
    "    column (string): Name of the column for the buckets used on the horizontal axis.\n",
    "\n",
    "    Returns:\n",
    "    None: Displays the chart.\n",
    "    \"\"\"\n",
    "    \n",
    "    if title is None:\n",
    "        title = 'Bar Chart'\n",
    "    \n",
    "    bin_counts = df[column].value_counts().sort_index()\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    bin_counts.plot(kind='bar', color='skyblue', edgecolor='black')\n",
    "    plt.title(title)\n",
    "    plt.xlabel(column)\n",
    "    plt.ylabel('Number')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# def generate_whisker_chart() # GENERATE A WHISKER CHART BASED ON VOLUME FOR AN IDENTIFIED COLUMN\n",
    "def generate_whisker_chart(df, columns, ylabel=None, title=None):\n",
    "    \"\"\"\n",
    "    GENERATE A WHISKER CHART BASED ON SELECTED COLUMNS\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): DataFrame \n",
    "    columns (string[]): Name of the columns for analysis.\n",
    "\n",
    "    Returns:\n",
    "    None: Displays the chart.\n",
    "    \"\"\"\n",
    "    \n",
    "    if title is None:\n",
    "        title = 'Bar Chart'\n",
    "        \n",
    "    # Create the box plot\n",
    "    # Define colors for the box plots\n",
    "    colors = {\n",
    "        'boxes': 'DarkOrange',\n",
    "        'whiskers': 'DarkOrange',\n",
    "        'medians': 'Blue',\n",
    "        'caps': 'Green'\n",
    "    }\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    try:\n",
    "        boxplot = df[columns].boxplot(\n",
    "            patch_artist=True,\n",
    "            boxprops=dict(facecolor='lightblue', color='DarkOrange'),\n",
    "            capprops=dict(color=colors['caps']),\n",
    "            whiskerprops=dict(color=colors['whiskers']),\n",
    "            flierprops=dict(markerfacecolor='red', marker='o', markersize=5, linestyle='none'),\n",
    "            medianprops=dict(color=colors['medians']),\n",
    "            vert=True\n",
    "        )\n",
    "    except ValueError as e:\n",
    "        print(\"ValueError encountered: \", e)\n",
    "        print(\"Ensure that the DataFrame contains data to generate a plot for the specified columns.\")\n",
    "        # Optionally, you can return or raise an error or handle it differently\n",
    "        \n",
    "    plt.title(title)\n",
    "    if ylabel:\n",
    "        plt.ylabel(ylabel)\n",
    "        \n",
    "    plt.xticks(rotation=45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COLLECT AND ANALYZE DATA FOR REPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RETRIEVE DATA\n",
    "from jira_fsp_extracts import fetch_jira_issues_to_dataframe\n",
    "\n",
    "final_query = '(' + query + ') and ((resolution is empty or resolution = Done) and status != \"Won\\'t Do\")'\n",
    "print(f\"JQL Query: {final_query}\")\n",
    "\n",
    "df = fetch_jira_issues_to_dataframe(jira_conn = j, jql_query = final_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cycle time calculations\n",
    "# Defintions:\n",
    "# Lead Time: Created until Done\n",
    "    # Cycle Time: Development Start until Done\n",
    "        # Development Time: Development Start until QA Review\n",
    "        # Validation Time: QA Start Until Done\n",
    "# + Release: Base Metric + Time from Done to Release (FUTURE)\n",
    "\n",
    "# only do calcs on done tickets\n",
    "df_ct_calcs = df[df['Done Date'].notna()].copy()\n",
    "if df_ct_calcs.shape[0] > 0:\n",
    "    df_ct_calcs[\"Lead Time (days)\"] = round((df_ct_calcs['Done Date'] - df_ct_calcs['Created Date']).dt.total_seconds() / (24 * 60 * 60),2)\n",
    "    df_ct_calcs[\"Cycle Time (days)\"] = round((df_ct_calcs['Done Date'] - df_ct_calcs['Development Date']).dt.total_seconds() / (24 * 60 * 60),2)\n",
    "    df_ct_calcs[\"CT Development Time (days)\"] = round((df_ct_calcs['Validation Date'] - df_ct_calcs['Development Date']).dt.total_seconds() / (24 * 60 * 60),2)\n",
    "    df_ct_calcs[\"CT Validation Time (days)\"] = round((df_ct_calcs['Done Date'] - df_ct_calcs['Validation Date']).dt.total_seconds() / (24 * 60 * 60),2)\n",
    "\n",
    "    # Calculate 'Release Time (days)' only when 'Release Date' is not None\n",
    "    df_ct_calcs[\"Release Time (days)\"] = df_ct_calcs.apply(\n",
    "        lambda row: round((row['Release Date'] - row['Done Date']).total_seconds() / (24 * 60 * 60), 2) if row['Release Date'] is not None else None,\n",
    "        axis=1)\n",
    "else:\n",
    "    df_ct_calcs[\"Lead Time (days)\"] = None\n",
    "    df_ct_calcs[\"Cycle Time (days)\"] = None\n",
    "    df_ct_calcs[\"CT Development Time (days)\"] = None\n",
    "    df_ct_calcs[\"CT Validation Time (days)\"] = None\n",
    "    df_ct_calcs[\"Release Time (days)\"] = None\n",
    "    \n",
    "# merge calced data into primary df\n",
    "# Drop the column if it exists\n",
    "df = df.drop(columns=[\"Lead Time (days)\",\"Cycle Time (days)\",\"CT Development Time (days)\",\"CT Validation Time (days)\",\"Release Time (days)\"], errors='ignore')\n",
    "df = df.merge(df_ct_calcs[['Issue Key',\"Lead Time (days)\",\"Cycle Time (days)\",\"CT Development Time (days)\",\"CT Validation Time (days)\",\"Release Time (days)\"]],on=\"Issue Key\",how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subsets for future reports\n",
    "df_filtered_standard_issues = df[df['Issue Type Category'] == \"STANDARD\"]\n",
    "df_filtered_sub_tasks_issues = df[df['Issue Type Category'] == \"SUBTASK\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Analyze Defects / other subtasks\n",
    "defects = df_filtered_sub_tasks_issues[df_filtered_sub_tasks_issues['Issue Type'] == \"Defect\"].groupby(['Parent Story']).agg({'Issue Key': 'count'}).rename(columns={'Issue Key': 'Defect Count'})\n",
    "sub_tasks_analysis = df_filtered_sub_tasks_issues.groupby(['Parent Story']).agg({'Issue Key': 'count'}).rename(columns={'Issue Key': 'All Subtasks Count'})\n",
    "sub_tasks_analysis = sub_tasks_analysis.merge(defects, on=\"Parent Story\", how=\"left\").fillna(0)\n",
    "sub_tasks_analysis['Defect Percentage'] = (sub_tasks_analysis['Defect Count'] / sub_tasks_analysis['All Subtasks Count']) * 100\n",
    "\n",
    "# Bucket the percentages\n",
    "bins = [0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "labels = ['0-10%', '10-20%', '20-30%', '30-40%', '40-50%', '50-60%', '60-70%', '70-80%', '80-90%', '90-100%']\n",
    "sub_tasks_analysis['Defect Percentage Bin'] = pd.cut(sub_tasks_analysis['Defect Percentage'], bins=bins, labels=labels, include_lowest=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BURNDOWN STACKED BAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_stacked_bar_chart(df_filtered_standard_issues, start_date=start_date, end_date=end_date, extrapolate_days=days_to_extrapolate, title=title + ' - Story Burndown (Remaining scope should be 0 by launch date)')\n",
    "generate_stacked_bar_chart(df_filtered_sub_tasks_issues, start_date=start_date, end_date=end_date, extrapolate_days=days_to_extrapolate, title=title + ' - Sub-Task Burndown (Remaining scope should be stable in a flow state)')\n",
    "generate_stacked_bar_chart(df, start_date=start_date, end_date=end_date, extrapolate_days=days_to_extrapolate, title=title + ' - All Burndown (Remaining scope should be 0 by launch date)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEFECTS PER STORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_bar_chart(sub_tasks_analysis,'Defect Percentage Bin',\"% of Defect Subtasks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CYCLE TIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_whisker_chart(df_filtered_standard_issues, \n",
    "                       columns=['Lead Time (days)', 'Cycle Time (days)', 'CT Development Time (days)', 'CT Validation Time (days)', 'Release Time (days)'], \n",
    "                       ylabel=\"Days\", title=\"Cycle Time Report - Stories\")\n",
    "generate_whisker_chart(df_filtered_sub_tasks_issues, \n",
    "                       columns=['Lead Time (days)', 'Cycle Time (days)', 'CT Development Time (days)', 'CT Validation Time (days)', 'Release Time (days)'], \n",
    "                       ylabel=\"Days\", title=\"Cycle Time Report - SubTasks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
